{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement_Learning_05.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNsEG/I0JRlo3340K9quLk5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rpdieego/Reinforcement_Learning/blob/master/Reinforcement_Learning_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oaWPaw6ogxR",
        "colab_type": "text"
      },
      "source": [
        "# Aproximation Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuorFUK7okj7",
        "colab_type": "text"
      },
      "source": [
        "#### Approximate Monte Carlo Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IfNfeA6ojx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import relevant libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjFwKSh2pFZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#grid world class\n",
        "\n",
        "class Grid: # Environment\n",
        "  def __init__ (self, rows, cols, start):\n",
        "    self.rows = rows\n",
        "    self.cols = cols\n",
        "    self.i = start[0]\n",
        "    self.j = start[1]\n",
        "\n",
        "  def set(self, rewards, actions):\n",
        "    # rewards is a dict of: (i,j): r\n",
        "    # actions is a dict of: (i,j): A\n",
        "    self.rewards = rewards\n",
        "    self.actions = actions\n",
        "\n",
        "  def set_state(self,s):\n",
        "    #force state\n",
        "    self.i = s[0]\n",
        "    self.j = s[1]\n",
        "\n",
        "  def current_state(self):\n",
        "    #return the current state\n",
        "    return (self.i, self.j)\n",
        "  \n",
        "  def is_terminal(self, s):\n",
        "    #if state is not listed in the actions dictionary, it means it's a terminal state\n",
        "    return s not in self.actions\n",
        "\n",
        "  def get_next_state(self, s, a):\n",
        "    i, j = s[0], s[1]\n",
        "    if a in self.actions[(i,j)]:\n",
        "      if a == 'U':\n",
        "        i -= 1\n",
        "      elif a =='D':\n",
        "        i += 1\n",
        "      elif a == 'R':\n",
        "        j += 1\n",
        "      elif a == 'L':\n",
        "        j -= 1\n",
        "    return i,j\n",
        "\n",
        "  def move(self, action):\n",
        "    # check if legal move first\n",
        "    if action in self.actions[(self.i, self.j)]:\n",
        "      if action == 'U':\n",
        "        self.i -= 1\n",
        "      elif action == 'D':\n",
        "        self.i += 1\n",
        "      elif action == 'R':\n",
        "        self.j += 1\n",
        "      elif action == 'L':\n",
        "        self.j -= 1\n",
        "    return self.rewards.get((self.i, self.j), 0)\n",
        "\n",
        "  def undo_move(self, action):\n",
        "    if action == 'U':\n",
        "      self.i += 1\n",
        "    elif action == 'D':\n",
        "      self.i -= 1\n",
        "    elif action == 'R':\n",
        "      self.j -= 1\n",
        "    elif action == 'L':\n",
        "      self.j += 1\n",
        "    #should never happen\n",
        "    assert(self.current_state() in self.all_states())\n",
        "  \n",
        "  def game_over(self):\n",
        "    #true if in a state where no actions are possible\n",
        "    return (self.i,self.j) not in self.actions\n",
        "\n",
        "  def all_states(self):\n",
        "    #either a position that has possible next actions or a positions that yields a reward\n",
        "    return set(self.actions.keys()) | set(self.rewards.keys())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2-i6uQjp6Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define grid environment\n",
        "\n",
        "def standard_grid():\n",
        "  g = Grid(3, 4, (2,0))\n",
        "  rewards = {(0,3): 1, (1,3): -1}\n",
        "  actions = {\n",
        "      (0,0): ('D','R'),\n",
        "      (0,1): ('L','R'),\n",
        "      (0,2): ('L','D','R'),\n",
        "      (1,0): ('U','D'),\n",
        "      (1,2): ('U', 'D', 'R'),\n",
        "      (2,0): ('U','R'),\n",
        "      (2,1): ('L','R'),\n",
        "      (2,2): ('L','R','U'),\n",
        "      (2,3): ('L','U')\n",
        "  }\n",
        "  g.set(rewards, actions)\n",
        "  return g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdoa2V4Dp-dC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define grid environment with step penalties\n",
        "\n",
        "def negative_grid(step_cost=-0.1):\n",
        "  # in this game we want to try to minimize the number of moves\n",
        "  # so we will penalize every move\n",
        "  g = standard_grid()\n",
        "  g.rewards.update({\n",
        "    (0, 0): step_cost,\n",
        "    (0, 1): step_cost,\n",
        "    (0, 2): step_cost,\n",
        "    (1, 0): step_cost,\n",
        "    (1, 2): step_cost,\n",
        "    (2, 0): step_cost,\n",
        "    (2, 1): step_cost,\n",
        "    (2, 2): step_cost,\n",
        "    (2, 3): step_cost,\n",
        "  })\n",
        "  return g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ4R9QQ2qBsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# auxiliar function to print values\n",
        "def print_values(V,g):\n",
        "  for i in range(g.rows):\n",
        "    print('-------------------------------')\n",
        "    for j in range(g.cols):\n",
        "      v = V.get((i,j),0)\n",
        "      if v>= 0:\n",
        "        print(\" %.2f|\" % v, end=\"\")\n",
        "      else:\n",
        "        print(\"%.2f|\" % v, end=\"\") # - sign take up an extra space\n",
        "    print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcxENSSkqHB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# auxiliar function to print policy\n",
        "def print_policy(P,g):\n",
        "  print('Policy \\n')\n",
        "  for i in range(g.rows):\n",
        "    print('-----------------------------')\n",
        "    for j in range(g.cols):\n",
        "      a = P.get((i,j),' ')\n",
        "      print(\"  %s  |\" % a, end='')\n",
        "    print('')\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8J9CRQuqInJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def play_game(grid, policy):\n",
        "\n",
        "  #returns a list of states and corresponding returns\n",
        "\n",
        "  #reset game to restart at random position\n",
        "  #we need to do this, because given our current deterministic policy\n",
        "  #we would never end up at certain states, but we still want to measure their value\n",
        "\n",
        "  start_states = list(grid.actions.keys())\n",
        "  start_idx = np.random.choice(len(start_states))\n",
        "  grid.set_state(start_states[start_idx])\n",
        "\n",
        "  s = grid.current_state()\n",
        "  # list of tuples of (state, reward)\n",
        "  states_and_rewards = [(s,0)]\n",
        "  while not  grid.game_over():\n",
        "    a = policy[s]\n",
        "    r = grid.move(a)\n",
        "    s = grid.current_state()\n",
        "    states_and_rewards.append((s,r))\n",
        "\n",
        "  #Calculate teh returns by working backwards from the terminal state\n",
        "  G = 0\n",
        "  states_and_returns = []\n",
        "  first = True\n",
        "  for s,r in reversed(states_and_rewards):\n",
        "    # value of terminal state is 0 by definition\n",
        "    #we should ignores the first state we encounter (terminal)\n",
        "    # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
        "    if first:\n",
        "      first = False\n",
        "    else:\n",
        "      states_and_returns.append((s,G))\n",
        "    \n",
        "    G = r + gamma*G\n",
        "\n",
        "  # we want it to be in order of state visited\n",
        "  states_and_returns.reverse()\n",
        "\n",
        "  return states_and_returns\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqXq1qsWqdx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_action(a):\n",
        "  #choose given a with probability 0.5\n",
        "  #choose some other a' != with probability 0.5/3\n",
        "  p = np.random.random()\n",
        "  if p < 0.5:\n",
        "    return a\n",
        "  else:\n",
        "    tmp = list(ALL_POSSIBLE_ACTIONS)\n",
        "    tmp.remove(a)\n",
        "    return np.random.choice(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIQGygQ3qh-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# definitions:\n",
        "\n",
        "#convergence parameter\n",
        "conv_parameter = 10e-4\n",
        "\n",
        "# discount factor\n",
        "gamma = 0.9\n",
        "\n",
        "#learning rate\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHIARWZcq5qm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "outputId": "03b97780-caa8-4710-f2af-bfc5e893c814"
      },
      "source": [
        "#### main\n",
        "\n",
        "#define grid environment\n",
        "grid = standard_grid()\n",
        "\n",
        "#print rewards\n",
        "print('Rewards:')\n",
        "print_values(grid.rewards, grid)\n",
        "print('\\n')\n",
        "\n",
        "# state -> action\n",
        "\n",
        "policy = {\n",
        "    (2,0): 'U',\n",
        "    (1,0): 'U',\n",
        "    (0,0): 'R',\n",
        "    (0,1): 'R',\n",
        "    (0,2): 'R',\n",
        "    (1,2): 'U',\n",
        "    (2,1): 'L',\n",
        "    (2,2): 'U',\n",
        "    (2,3): 'L',\n",
        "}\n",
        "\n",
        "#initialize Theta\n",
        "# our model is V_hat = theta.dot(x)\n",
        "# where x = [row, col, row*col, 1] -> 1 for bias term\n",
        "theta = np.random.randn(4) / 2\n",
        "\n",
        "def s2x(s):\n",
        "  return np.array([s[0] - 1, s[1] - 1.5, s[0]*s[1] - 3, 1])\n",
        "\n",
        "# repeat until convergence\n",
        "deltas = []\n",
        "t = 1.0\n",
        "for it in range(20000):\n",
        "\n",
        "  # decreasing learning rate\n",
        "  if it % 100 == 0:\n",
        "    t += 0.01\n",
        "  alpha = learning_rate / t\n",
        "\n",
        "  # generate an episode using pi\n",
        "  biggest_change = 0\n",
        "  states_and_returns = play_game(grid, policy)\n",
        "  seen_states = set()\n",
        "\n",
        "  for s,G in states_and_returns:\n",
        "    #check if we already seen s (first visit MC policy evaluation)\n",
        "    if s not in seen_states:\n",
        "      old_theta = theta.copy()\n",
        "      x = s2x(s)\n",
        "      V_hat = theta.dot(x)\n",
        "      # grad (V_hat) wrt theta = x\n",
        "      theta += alpha*(G - V_hat)*x\n",
        "      biggest_change = max(biggest_change, np.abs(old_theta - theta).sum())\n",
        "      seen_states.add(s)\n",
        "  deltas.append(biggest_change)\n",
        "\n",
        "plt.plot(deltas)\n",
        "plt.show()\n",
        "\n",
        "# obtain predicted values\n",
        "V = {}\n",
        "states = grid.all_states()\n",
        "for s in states:\n",
        "  if s in grid.actions:\n",
        "    V[s] = theta.dot(s2x(s))\n",
        "  else:\n",
        "    #terminal state or state we cannot otherwise get to\n",
        "    V[s] = 0\n",
        "\n",
        "#print values\n",
        "print('Final Values:')\n",
        "print_values(V,grid)\n",
        "print('\\n')\n",
        "\n",
        "#print policy\n",
        "print('Final Policy')\n",
        "print_policy(policy, grid)\n",
        "print('\\n')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rewards:\n",
            "-------------------------------\n",
            " 0.00| 0.00| 0.00| 1.00|\n",
            "-------------------------------\n",
            " 0.00| 0.00| 0.00|-1.00|\n",
            "-------------------------------\n",
            " 0.00| 0.00| 0.00| 0.00|\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Values:\n",
            "-------------------------------\n",
            " 0.80| 0.90| 1.00| 0.00|\n",
            "-------------------------------\n",
            " 0.73| 0.00| 0.87| 0.00|\n",
            "-------------------------------\n",
            " 0.65| 0.70| 0.74| 0.79|\n",
            "\n",
            "\n",
            "Final Policy\n",
            "Policy \n",
            "\n",
            "-----------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "-----------------------------\n",
            "  U  |     |  U  |     |\n",
            "-----------------------------\n",
            "  U  |  L  |  U  |  L  |\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RxbGDFX0bGX",
        "colab_type": "text"
      },
      "source": [
        "#### TD (0) Semi-Gradient Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-9iZf54xad-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def play_game(grid,policy):\n",
        "  #return a list of states and corresponding rewards\n",
        "  #start at the designated start state (2,0)\n",
        "  s = (2,0)\n",
        "  grid.set_state(s)\n",
        "  #list of tuples of (state, reward)\n",
        "  states_and_rewards = [(s,0)]\n",
        "  while not grid.game_over():\n",
        "    a = policy[s]\n",
        "    a = random_action(a)\n",
        "    r = grid.move(a)\n",
        "    s = grid.current_state()\n",
        "    states_and_rewards.append((s,r))\n",
        "  return states_and_rewards"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlBogcAz0rwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# definitions\n",
        "\n",
        "#convergence parameter\n",
        "conv_parameter = 10e-4\n",
        "\n",
        "# discount factor\n",
        "gamma = 0.9\n",
        "\n",
        "# learning rate\n",
        "alpha = 0.1\n",
        "\n",
        "# Action Space\n",
        "ALL_POSSIBLE_ACTIONS = ('U','D','L','R')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UhMoGkr0x3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "  def __init__(self):\n",
        "    self.theta = np.random.randn(4) /2\n",
        "\n",
        "  # state to feature\n",
        "  def s2x(self,s):\n",
        "    return np.array([s[0] - 1, s[1] - 1.5, s[0]*s[1] - 3, 1])\n",
        "  \n",
        "  def predict(self, s):\n",
        "    x = self.s2x(s)\n",
        "    return self.theta.dot(x)\n",
        "  \n",
        "  def grad(self,s):\n",
        "    return self.s2x(s)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVS9s9Cx1326",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "outputId": "e06ef8e1-eebb-423f-f0bd-63df8aa0e84b"
      },
      "source": [
        "### main section\n",
        "\n",
        "#grid environment\n",
        "grid = standard_grid()\n",
        "\n",
        "# print rewards\n",
        "print('Rewards :')\n",
        "print_values(grid.rewards, grid)\n",
        "print('\\n')\n",
        "\n",
        "# state -> action\n",
        "\n",
        "policy = {\n",
        "    (2,0): 'U',\n",
        "    (1,0): 'U',\n",
        "    (0,0): 'R',\n",
        "    (0,1): 'R',\n",
        "    (0,2): 'R',\n",
        "    (1,2): 'R',\n",
        "    (2,1): 'R',\n",
        "    (2,2): 'R',\n",
        "    (2,3): 'U',\n",
        "}\n",
        "\n",
        "# define model\n",
        "model = Model()\n",
        "\n",
        "#empty list to store deltas\n",
        "deltas = []\n",
        "\n",
        "# repeat until convergence\n",
        "k = 1.0\n",
        "for it in range(20000):\n",
        "  \n",
        "  # descending learning rate\n",
        "  if it % 10 == 0:\n",
        "    k += 0.01\n",
        "  alpha_k = alpha/k\n",
        "  biggest_change = 0\n",
        "\n",
        "  # generate an episode using pi\n",
        "  states_and_rewards = play_game(grid,policy)\n",
        "\n",
        "  # first (s,r) tuple is a state we start in and 0 (no reward at start)\n",
        "  # last (s,r) tuples is the terminal state and 0 (value is 0 by definition)\n",
        "\n",
        "  for t in range(len(states_and_rewards) -1):\n",
        "    s, _ = states_and_rewards[t]\n",
        "    s2, r = states_and_rewards[t+1]\n",
        "\n",
        "    # Update V(s) as we experience the episode\n",
        "\n",
        "    old_theta = model.theta.copy()\n",
        "    if grid.is_terminal(s2):\n",
        "      target = r\n",
        "    else:\n",
        "      target = r + gamma*model.predict(s2)\n",
        "    \n",
        "    model.theta += alpha_k*(target - model.predict(s))*model.grad(s)\n",
        "    biggest_change = max(biggest_change, np.abs(old_theta - model.theta).sum())\n",
        "\n",
        "  deltas.append(biggest_change)\n",
        "\n",
        "#plot deltas\n",
        "plt.plot(deltas)\n",
        "plt.show()\n",
        "\n",
        "#obtain predicted values\n",
        "V = {}\n",
        "states = grid.all_states()\n",
        "for s in states:\n",
        "  if s in grid.actions:\n",
        "    V[s] = model.predict(s)\n",
        "  else:\n",
        "    #terminal state\n",
        "    V[s] = 0\n",
        "\n",
        "\n",
        "#print values\n",
        "print('Final Values:')\n",
        "print_values(V,grid)\n",
        "print('\\n')\n",
        "\n",
        "#print policy\n",
        "print('Final Policy')\n",
        "print_policy(policy, grid)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rewards :\n",
            "-------------------------------\n",
            " 0.00| 0.00| 0.00| 1.00|\n",
            "-------------------------------\n",
            " 0.00| 0.00| 0.00|-1.00|\n",
            "-------------------------------\n",
            " 0.00| 0.00| 0.00| 0.00|\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Values:\n",
            "-------------------------------\n",
            " 0.25| 0.35| 0.46| 0.00|\n",
            "-------------------------------\n",
            " 0.12| 0.00|-0.11| 0.00|\n",
            "-------------------------------\n",
            "-0.01|-0.35|-0.68|-1.02|\n",
            "\n",
            "\n",
            "Final Policy\n",
            "Policy \n",
            "\n",
            "-----------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "-----------------------------\n",
            "  U  |     |  R  |     |\n",
            "-----------------------------\n",
            "  U  |  R  |  R  |  U  |\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXxCbRTzAqQr",
        "colab_type": "text"
      },
      "source": [
        "#### Semi Gradient SARSA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5mDvqM23KXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_dict(d):\n",
        "  # returns the argmax (key) and max (value) from a dictionary\n",
        "  # put this into a function since we are using it so often\n",
        "  max_key = None\n",
        "  max_val = float('-inf')\n",
        "  for k, v in d.items():\n",
        "    if v > max_val:\n",
        "      max_val = v\n",
        "      max_key = k\n",
        "  return max_key, max_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wGihQN3BiTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_action(a, eps=0.1):\n",
        "  #we'll use episilon-soft to ensure all states are visited\n",
        "  p = np.random.random()\n",
        "  if p < (1-eps):\n",
        "    return a\n",
        "  else:\n",
        "    return np.random.choice(ALL_POSSIBLE_ACTIONS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqmwRo9DA_Sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SA2IDX = {}\n",
        "IDX = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_cBMCp_AxbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "  def __init__(self):\n",
        "    self.theta = np.random.randn(25) / np.sqrt(25)\n",
        "    # if we use SA2IDX, a one-hot encoding for every (s,a) pair\n",
        "    # in reality we wouldn't want to do this b/c we have just\n",
        "    # as many params as before\n",
        "    # print \"D:\", IDX\n",
        "    # self.theta = np.random.randn(IDX) / np.sqrt(IDX)\n",
        "\n",
        "  def sa2x(self, s, a):\n",
        "    # NOTE: using just (r, c, r*c, u, d, l, r, 1) is not expressive enough\n",
        "    return np.array([\n",
        "      s[0] - 1              if a == 'U' else 0,\n",
        "      s[1] - 1.5            if a == 'U' else 0,\n",
        "      (s[0]*s[1] - 3)/3     if a == 'U' else 0,\n",
        "      (s[0]*s[0] - 2)/2     if a == 'U' else 0,\n",
        "      (s[1]*s[1] - 4.5)/4.5 if a == 'U' else 0,\n",
        "      1                     if a == 'U' else 0,\n",
        "      s[0] - 1              if a == 'D' else 0,\n",
        "      s[1] - 1.5            if a == 'D' else 0,\n",
        "      (s[0]*s[1] - 3)/3     if a == 'D' else 0,\n",
        "      (s[0]*s[0] - 2)/2     if a == 'D' else 0,\n",
        "      (s[1]*s[1] - 4.5)/4.5 if a == 'D' else 0,\n",
        "      1                     if a == 'D' else 0,\n",
        "      s[0] - 1              if a == 'L' else 0,\n",
        "      s[1] - 1.5            if a == 'L' else 0,\n",
        "      (s[0]*s[1] - 3)/3     if a == 'L' else 0,\n",
        "      (s[0]*s[0] - 2)/2     if a == 'L' else 0,\n",
        "      (s[1]*s[1] - 4.5)/4.5 if a == 'L' else 0,\n",
        "      1                     if a == 'L' else 0,\n",
        "      s[0] - 1              if a == 'R' else 0,\n",
        "      s[1] - 1.5            if a == 'R' else 0,\n",
        "      (s[0]*s[1] - 3)/3     if a == 'R' else 0,\n",
        "      (s[0]*s[0] - 2)/2     if a == 'R' else 0,\n",
        "      (s[1]*s[1] - 4.5)/4.5 if a == 'R' else 0,\n",
        "      1                     if a == 'R' else 0,\n",
        "      1\n",
        "    ])\n",
        "    # if we use SA2IDX, a one-hot encoding for every (s,a) pair\n",
        "    # in reality we wouldn't want to do this b/c we have just\n",
        "    # as many params as before\n",
        "    # x = np.zeros(len(self.theta))\n",
        "    # idx = SA2IDX[s][a]\n",
        "    # x[idx] = 1\n",
        "    # return x\n",
        "\n",
        "  def predict(self, s, a):\n",
        "    x = self.sa2x(s, a)\n",
        "    return self.theta.dot(x)\n",
        "\n",
        "  def grad(self, s, a):\n",
        "    return self.sa2x(s, a)\n",
        "\n",
        "\n",
        "def getQs(model, s):\n",
        "  # we need Q(s,a) to choose an action\n",
        "  # i.e. a = argmax[a]{ Q(s,a) }\n",
        "  Qs = {}\n",
        "  for a in ALL_POSSIBLE_ACTIONS:\n",
        "    q_sa = model.predict(s, a)\n",
        "    Qs[a] = q_sa\n",
        "  return Qs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl3Gcr32A-Uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fadfa7fe-86bd-4316-fc9e-6daa7a27e8fa"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  # NOTE: if we use the standard grid, there's a good chance we will end up with\n",
        "  # suboptimal policies\n",
        "  # e.g.\n",
        "  # ---------------------------\n",
        "  #   R  |   R  |   R  |      |\n",
        "  # ---------------------------\n",
        "  #   R* |      |   U  |      |\n",
        "  # ---------------------------\n",
        "  #   U  |   R  |   U  |   L  |\n",
        "  # since going R at (1,0) (shown with a *) incurs no cost, it's OK to keep doing that.\n",
        "  # we'll either end up staying in the same spot, or back to the start (2,0), at which\n",
        "  # point we whould then just go back up, or at (0,0), at which point we can continue\n",
        "  # on right.\n",
        "  # instead, let's penalize each movement so the agent will find a shorter route.\n",
        "  #\n",
        "  # grid = standard_grid()\n",
        "  grid = negative_grid(step_cost=-0.1)\n",
        "\n",
        "  # print rewards\n",
        "  print(\"rewards:\")\n",
        "  print_values(grid.rewards, grid)\n",
        "\n",
        "  # no policy initialization, we will derive our policy from most recent Q\n",
        "  # enumerate all (s,a) pairs, each will have its own weight in our \"dumb\" model\n",
        "  # essentially each weight will be a measure of Q(s,a) itself\n",
        "  states = grid.all_states()\n",
        "  for s in states:\n",
        "    SA2IDX[s] = {}\n",
        "    for a in ALL_POSSIBLE_ACTIONS:\n",
        "      SA2IDX[s][a] = IDX\n",
        "      IDX += 1\n",
        "\n",
        "  # initialize model\n",
        "  model = Model()\n",
        "\n",
        "  # repeat until convergence\n",
        "  t = 1.0\n",
        "  t2 = 1.0\n",
        "  deltas = []\n",
        "  for it in range(20000):\n",
        "    if it % 100 == 0:\n",
        "      t += 0.01\n",
        "      t2 += 0.01\n",
        "    if it % 1000 == 0:\n",
        "      print(\"it:\", it)\n",
        "    alpha_t = alpha / t2\n",
        "\n",
        "    # instead of 'generating' an epsiode, we will PLAY\n",
        "    # an episode within this loop\n",
        "    s = (2, 0) # start state\n",
        "    grid.set_state(s)\n",
        "\n",
        "    # get Q(s) so we can choose the first action\n",
        "    Qs = getQs(model, s)\n",
        "\n",
        "    # the first (s, r) tuple is the state we start in and 0\n",
        "    # (since we don't get a reward) for simply starting the game\n",
        "    # the last (s, r) tuple is the terminal state and the final reward\n",
        "    # the value for the terminal state is by definition 0, so we don't\n",
        "    # care about updating it.\n",
        "    a = max_dict(Qs)[0]\n",
        "    a = random_action(a, eps=0.5/t) # epsilon-greedy\n",
        "    biggest_change = 0\n",
        "    while not grid.game_over():\n",
        "      r = grid.move(a)\n",
        "      s2 = grid.current_state()\n",
        "\n",
        "      # we need the next action as well since Q(s,a) depends on Q(s',a')\n",
        "      # if s2 not in policy then it's a terminal state, all Q are 0\n",
        "      old_theta = model.theta.copy()\n",
        "      if grid.is_terminal(s2):\n",
        "        model.theta += alpha_t*(r - model.predict(s, a))*model.grad(s, a)\n",
        "      else:\n",
        "        # not terminal\n",
        "        Qs2 = getQs(model, s2)\n",
        "        a2 = max_dict(Qs2)[0]\n",
        "        a2 = random_action(a2, eps=0.5/t) # epsilon-greedy\n",
        "\n",
        "        # we will update Q(s,a) AS we experience the episode\n",
        "        model.theta += alpha_t*(r + gamma*model.predict(s2, a2) - model.predict(s, a))*model.grad(s, a)\n",
        "        \n",
        "        # next state becomes current state\n",
        "        s = s2\n",
        "        a = a2\n",
        "\n",
        "      biggest_change = max(biggest_change, np.abs(model.theta - old_theta).sum())\n",
        "    deltas.append(biggest_change)\n",
        "\n",
        "  plt.plot(deltas)\n",
        "  plt.show()\n",
        "\n",
        "  # determine the policy from Q*\n",
        "  # find V* from Q*\n",
        "  policy = {}\n",
        "  V = {}\n",
        "  Q = {}\n",
        "  for s in grid.actions.keys():\n",
        "    Qs = getQs(model, s)\n",
        "    Q[s] = Qs\n",
        "    a, max_q = max_dict(Qs)\n",
        "    policy[s] = a\n",
        "    V[s] = max_q\n",
        "\n",
        "  print(\"values:\")\n",
        "  print_values(V, grid)\n",
        "  print(\"policy:\")\n",
        "  print_policy(policy, grid)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rewards:\n",
            "-------------------------------\n",
            "-0.10|-0.10|-0.10| 1.00|\n",
            "-------------------------------\n",
            "-0.10| 0.00|-0.10|-1.00|\n",
            "-------------------------------\n",
            "-0.10|-0.10|-0.10|-0.10|\n",
            "it: 0\n",
            "it: 1000\n",
            "it: 2000\n",
            "it: 3000\n",
            "it: 4000\n",
            "it: 5000\n",
            "it: 6000\n",
            "it: 7000\n",
            "it: 8000\n",
            "it: 9000\n",
            "it: 10000\n",
            "it: 11000\n",
            "it: 12000\n",
            "it: 13000\n",
            "it: 14000\n",
            "it: 15000\n",
            "it: 16000\n",
            "it: 17000\n",
            "it: 18000\n",
            "it: 19000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "values:\n",
            "-------------------------------\n",
            " 0.47| 0.69| 0.96| 0.00|\n",
            "-------------------------------\n",
            " 0.35| 0.00| 0.50| 0.00|\n",
            "-------------------------------\n",
            " 0.21| 0.00| 0.07| 0.43|\n",
            "policy:\n",
            "Policy \n",
            "\n",
            "-----------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "-----------------------------\n",
            "  U  |     |  U  |     |\n",
            "-----------------------------\n",
            "  U  |  L  |  U  |  U  |\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXy-8hp-BDC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}